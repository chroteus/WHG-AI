[Task 0 - Get data]
===================
    <??> I need to get data from game as an array I can feed into neural network.
         Plus, I need to read off the score.

    -> Added second screen and took screenshots of it to get game data
    -> Used OCR to read level and death number
    -> Along the way realized, both monitors run off the same x11 server,
       so I wouldn't be able to use computer while AI is runninng

    -> Set up a VM with Bodhi Linux
    -> First, tried to use VBox API to take screenshot for game data, but it's broken :(
    -> Then, setup a VNC server on guest and got game data using a VNC library.
    -> Still used OCR to read deaths and level, but this time made it more reliable (increased resolution)

    <!!> Challenges faced
    1. Goals aren't distinct in grayscale,
       plus, coins and enemies are hard to distinct without color
        ->> Had to use all 3 channels, instead of preferred 1.


[Task 1 - Objective]
==================================
    <??> We cannot reward the agent unless we can quantify how well it is doing.
         Using a human is infeasible as the human is lazy, so we'll resort to using
         a neural net which will look at the screen the same way as agent, and output
         a number 0-1 which will tell how well our agent is performing.

    -> Generated small amounts of data, trained.
        -> The result WAS terrible. I'm sure there wasn't enough data and I didn't validate.

    ![Run 4 and 5]
    -> Increased data, trained.
        -> Result was still dogshite, changed loss to BCE, still bad.

    ![Run 6]
    -> Increased input image from 96x56 to 144x84 (x1.5). Regenerated train data
       with new resolution, on only the 1st level to save time. Loss = L1

        (For step=400)
        -> Result is better, it does quantify the value of the state well, and can
        kinda recognize when player passes half the screen,
        but it STILL regards enemies as important when quantifying position.

    [ValueNet conclusion #1 after run]
    ->> Going to stop using neural nets for ValueNet. Although it somewhat works,
    it's not robust enough, and gives importance to enemies when evaluating.

        (For step=140 [val err is minimum])
        -> Jumps all over the place, but still recognizes when the player has passed half the screen.

    ![Run 7]
    -> For experiment, remove convolutional layer, reduce image size back to 96x56,
       but use linear layers ONLY (no convlayers!)t
        ->  Result = Does not converge.
           ## DIDNT RECORD ##

    ![Run 8]
    -> Used conv layers more.
        -> Result = Not much change, though it looked promising.

    [ValueNet insight!]
    -> What if we simply use mean of last 5-10 values instead of just a value.
        -> Result: It works MUCH better, and somewhat cancels out effect of enemies on result.
        -> Gonna explore more in further runs.
        -> #R# Recorded as Run 8.5

    [!!! Embarassing]
    -> Discovered a very embarassing bug which made %75 of data not being used.
       No wonder I get these awful results.

    ![Run 10 (9 not interesting)]
    -> SUCCESS!!!!!!
       Fixing the bug had a HUGE effect on performance. It's SO,SO much better now.
       However, it still needs to be averaged out as blue critters are still somewhat important.

    ![Run 11 (Classification instead of regression)]
    -> Result = Classifier does not work. Whoops.

    ![Run 12 (As a test, use MSE instead of BCE), Classification]
    -> Result = Even worse.


    ![Runs 13 - 16]
    -> Made net architecture a bit more complex, which had a very positive effect on
       performance.
       HOWEVER: I've found a blind spot which rewarded player too much at a certain spot on start.

    ![Runs 17 and 18] <<== Chosen nets!
    ->  Fixed blind spot by throwing more data at net. ValueNet can now be used.
        There's still noise picked up due to blue critters, but it's less and
        averaging trick works just fine.
        I'm also going to ensemble both Net #17 and Net #18 to even further
        reduce overall noise.

    [Conclusion of Task 1]
    ->  Batching bug severely affected my productivity, and I almost gave up
        on using neural nets for objective, but I've finally made it.
        Judging by timestamps on videos, it took me a week to finally create ValueNet.
        Admittedly, it felt like a longer time.

[Task 2 - Learning!]
    
